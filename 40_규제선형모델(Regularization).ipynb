{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a953f79",
   "metadata": {},
   "source": [
    "# 규제 선형 모델 Regularization\n",
    "\n",
    "25.07.22 (화) 11주 49일차\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5cc2a8",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "\n",
    "![규제선형모델1](images\\규제선형모델1.png)\n",
    "\n",
    "규제는 과적합 모델(Overfitting Model)을 일반화된 모델(Generalization)로 변환하여 모델이 학습 데이터에 지나치게 맞춰지는 것을 방지하고, 새로운 데이터에도 잘 작동하도록 도와준다.  규제는 모델의 복잡도를 제한하여 더 안정적이고 일반화된 모델을 만들며, 이는 예측 성능을 향상시키는 데 중요한 역할을 한다. \n",
    "\n",
    "- 선형 모델의 비용함수는 RSS, 즉 실제 값과 예측값의 차이를 최소화하는 것을 고려한 방식이다.  이 경우 학습 데이터에 지나치게 맞추게 되어 회귀 계수가 쉽게 커지고, 변동성이 오히려 커져서 테스트 데이터 세트에서는 예측 성능이 저하되기 쉬운 과적합이 우려되었다.\n",
    "- 하지만 **손실 함수만 최소화**하면, 훈련 데이터에 과도하게 적합하는 **과적합(overfitting)** 이 발생할 수 있음.\n",
    "- 방지를 위해 **정규화(regularization)** 를 도입하여 **계수(가중치)의 크기에 제약(penalty)** 을 부여함.\n",
    "- 이 제약 항에 **알파(𝛼)** 를 곱해서 손실 함수와의 균형을 조절함.\n",
    "\n",
    "총 Cost=Loss+α⋅Penalty $= \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\alpha \\sum_{j=1}^{p} w_j^2$\n",
    "\n",
    "규제는 크게 L2 방식과 L1 방식으로 나눈다.  ****\n",
    "\n",
    "**L2 규제를 적용한 릿지 회귀, L1 규제를 적용한 라쏘 회귀,  두 가지 규제를 합한 것이 엘라스틱넷**이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627e47d3",
   "metadata": {},
   "source": [
    "# Ridge  & Lasso\n",
    "\n",
    "**Ridge와 Lasso**는 기존 다중 선형 회귀 모델의 손실 함수에 계수 크기에 대한 **페널티를 더한 함수**를 사용하여 모델을 학습한다.\n",
    "\n",
    "![Ridge&Lasso](images\\Ridge&Lasso.png)\n",
    "\n",
    "## Ridge(L2 규제) 회귀\n",
    "\n",
    "![Ridge(L2규제)회귀](images\\Ridge(L2규제)회귀.png)\n",
    "\n",
    "이런  비용함수를 사용하는 회귀 함수를 **릿지 회귀Ridge Regression** 또는 능형 회귀라고 한다.   \n",
    "\n",
    "알파는 사용자가 정의한 하이퍼파라미터로 모델을 얼마나 규제할지 그 정도를 조절하는 일을 한다. 만일 알파가 0의 값을 가지면 두번째 항 전체가 0이 되므로 원래 비용함수와 동일할 것이다.  반대로 알파가 매우 큰 값을 가지면 모든 파라미터가 거의 0에 가까워 져서 결국 데이터의 평균을 지나는 수평선이 될 것이다.(과소적합)  **하지만 릿지 회귀의 경우 회귀 계수를 0으로 만들지는 않는다.**\n",
    "\n",
    "![Ridge(L2규제)회귀2](images\\Ridge(L2규제)회귀2.png)\n",
    "\n",
    "**규제가 강해질수록 (α 증가)** → 예측 오차/RSS 증가 (덜 민감하게 됨) →  **일부 입력 변수의 계수가 0에 가까워져서 사실상 모델이 사용하는 입력변수의 수가 줄어드는 효과**\n",
    "\n",
    "릿지 회귀는 전체 계수의 크기를 최대한 작게(분산을 줄임) 만드는 동시에 회귀모델의 성능을 올리게 된다. \n",
    "\n",
    "입력변수가 완전히 제거되진 않지만, **영향력이 매우 작아져 사실상 '무시'되는 수준**으로 감소한다.\n",
    " \n",
    "그래서 Ridge의 훈련 데이터는 전체적으로 선형 회귀의 점수보다 낮으나 **데이터가 충분히 많으면 규제항은 덜 중요해져서 릿지 회귀와 선형 회귀의 성능은 같아지게 된다**.  그래서 벌칙 penalty 라고 부르기도 한다.\n",
    "\n",
    "![Ridge(L2규제)회귀3](images\\Ridge(L2규제)회귀3.png)\n",
    "\n",
    "<aside>\n",
    "💡\n",
    "\n",
    "**1) 현재 데이터를 조금 덜 훌륭하게 설명하는 모델을 얻게 되더라도**, \n",
    "\n",
    "**2) 미래 데이터에 대한 예측 성능이 조금 더 좋은 모델**을 만든다.\n",
    "\n",
    "</aside>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6277baeb",
   "metadata": {},
   "source": [
    "# 규제 회귀모델 (Regularization Regression Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73119544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2c5f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성 (Ridge 회귀 실습용)\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 예시 데이터 생성\n",
    "X, y = make_regression(n_samples=100, n_features=10, noise=10, random_state=42)\n",
    "\n",
    "# train/test 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"✅ 데이터 준비 완료!\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"학습 데이터: {X_train.shape}\")  \n",
    "print(f\"테스트 데이터: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ad224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge 회귀 실행\n",
    "ridge = Ridge(alpha=1.0)  # alpha는 규제 강도\n",
    "ridge.fit(X_train, y_train)\n",
    "pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "print(\"🔍 [릿지 회귀 결과]\")\n",
    "print(\"MSE:\", mean_squared_error(y_test, pred_ridge))\n",
    "print(\"R²:\", r2_score(y_test, pred_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd529d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[릿지 회귀]\n",
      "MSE: 127.60013070944176\n",
      "R2: 0.9978774507478436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Ridge 모델을 만들기 전에 이 코드를 추가해주세요!\n",
    "\n",
    "# --- 데이터 분리 코드 ---\n",
    "# 가지고 있는 전체 데이터(X)와 전체 정답(y)을 넣습니다.\n",
    "# test_size=0.2는 전체 데이터 중 20%를 테스트용으로 사용하겠다는 의미입니다.\n",
    "# random_state는 코드를 다시 실행해도 항상 똑같은 방식으로 데이터를 나누기 위해 설정하는 값입니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- 이제 원래 코드를 실행하면 정상적으로 작동합니다 ---\n",
    "# 3. 릿지 회귀\n",
    "ridge = Ridge(alpha=1.0) # alpha는 규제 강도\n",
    "ridge.fit(X_train, y_train) # 이제 X_train이 존재하므로 에러가 발생하지 않습니다.\n",
    "pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "print(\"\\n[릿지 회귀]\")\n",
    "print(\"MSE:\", mean_squared_error(y_test, pred_ridge))\n",
    "print(\"R2:\", r2_score(y_test, pred_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08249bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127.60013070944176, 0.9978774507478436)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, pred_ridge)\n",
    "r2  = r2_score(y_test, pred_ridge)\n",
    "mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61713dbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1467610003.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m다항 회귀 모델\u001b[39m\n       ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "다항 회귀 모델\n",
    "15.5, 0.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8c44902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4d6b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv.fit(X_train, y_train)\n",
    "ridge_preds = ridge_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a09d569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge cv mse: 102.793230, r2 : 0.998290\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ridge_mse = mean_squared_error(y_test, ridge_preds)\n",
    "ridge_r2 = r2_score(y_test, ridge_preds)\n",
    "print(f'ridge cv mse: {ridge_mse:4f}, r2 : {ridge_r2:4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f179bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cf2047",
   "metadata": {},
   "source": [
    "## Lasso alpha=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a3ea29",
   "metadata": {},
   "source": [
    "## LassoCV\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hipython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
