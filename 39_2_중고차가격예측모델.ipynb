{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "main-title",
   "metadata": {},
   "source": [
    "# ğŸš— ì¤‘ê³ ì°¨ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ ì‹¤ìŠµ ë³´ê³ ì„œ\n",
    "**íŒŒì¼ ìœ„ì¹˜**: `C:\\\\githome\\\\9-11week_py_statistics\\\\ì¤‘ê³ ì°¨ê°€ê²©ì˜ˆì¸¡ëª¨ë¸_ì™„ì „íŒ.ipynb`\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”\n",
    "\n",
    "### ğŸ¯ ëª©ì \n",
    "UAEì˜ ì¤‘ê³ ì°¨ ê±°ë˜ í”Œë«í¼ **Dubizzle** ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì¤‘ê³ ì°¨ ê°€ê²©ì„ ì˜ˆì¸¡í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ê°œë°œí•˜ê³  ì„±ëŠ¥ì„ ë¶„ì„í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ“Š ì‚¬ìš© ë°ì´í„°\n",
    "- **íŒŒì¼ëª…**: `Dubizzle_used_car_sales.csv`\n",
    "- **ì¶œì²˜**: UAE ì¤‘ê³ ì°¨ ê±°ë˜ í”Œë«í¼ Dubizzle\n",
    "- **ì£¼ìš” ë³€ìˆ˜**: ë¸Œëœë“œ, ëª¨ë¸, ì—°ì‹, ì£¼í–‰ê±°ë¦¬, ê°€ê²©, ì°¨ì²´íƒ€ì…, ì—°ë£Œíƒ€ì… ë“±\n",
    "\n",
    "### ğŸ”¬ ë¶„ì„ ë°©ë²•ë¡ \n",
    "- **ëª¨ë¸**: ì„ í˜•íšŒê·€, Ridge, Lasso, ElasticNet, ë‹¤í•­íšŒê·€\n",
    "- **ì „ì²˜ë¦¬**: ê²°ì¸¡ê°’ ì²˜ë¦¬, ë¼ë²¨ ì¸ì½”ë”©, í‘œì¤€í™”\n",
    "- **í‰ê°€ì§€í‘œ**: MAE, MSE, RMSE, RÂ² Score\n",
    "\n",
    "### ğŸ“ˆ ê¸°ëŒ€ ì„±ê³¼\n",
    "- ì¤‘ê³ ì°¨ ê°€ê²© ì˜ˆì¸¡ ì •í™•ë„ 80% ì´ìƒ ë‹¬ì„±\n",
    "- ê°€ê²© ê²°ì • ì£¼ìš” ìš”ì¸ ë¶„ì„\n",
    "- ì‹¤ë¬´ í™œìš© ê°€ëŠ¥í•œ ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-section",
   "metadata": {},
   "source": [
    "## ğŸ“¦ 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¶„ì„ ë° ì¡°ì‘ì„ ìœ„í•œ ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import pandas as pd              # ë°ì´í„°í”„ë ˆì„ ì¡°ì‘\n",
    "import numpy as np               # ìˆ˜ì¹˜ ì—°ì‚°\n",
    "import matplotlib.pyplot as plt  # ê·¸ë˜í”„ ìƒì„±\n",
    "import seaborn as sns            # í†µê³„ ì‹œê°í™”\n",
    "\n",
    "# ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë° ì „ì²˜ë¦¬\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (ê·¸ë˜í”„ì—ì„œ í•œê¸€ ê¹¨ì§ ë°©ì§€)\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# ì¶œë ¥ ì„¤ì •\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì„í¬íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"ğŸ“ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: C:\\\\githome\\\\9-11week_py_statistics\")\n",
    "print(f\"ğŸ“Š pandas ë²„ì „: {pd.__version__}\")\n",
    "print(f\"ğŸ”¢ numpy ë²„ì „: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading-section",
   "metadata": {},
   "source": [
    "## ğŸ“ 2. ë°ì´í„° ë¡œë”© ë° ê¸°ë³¸ íƒìƒ‰\n",
    "\n",
    "UAE ì¤‘ê³ ì°¨ ê±°ë˜ ë°ì´í„°ë¥¼ ë¡œë”©í•˜ê³  ê¸°ë³¸ì ì¸ ë°ì´í„° êµ¬ì¡°ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë”©\n",
    "print(\"ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...\")\n",
    "try:\n",
    "    df = pd.read_csv('data1/Dubizzle_used_car_sales.csv', encoding='utf-8')\n",
    "    print(\"âœ… ë°ì´í„° ë¡œë”© ì„±ê³µ!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ data1 í´ë”ì— Dubizzle_used_car_sales.csv íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# ë°ì´í„° ê¸°ë³¸ ì •ë³´\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ë°ì´í„° ê¸°ë³¸ ì •ë³´\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ğŸ“ ë°ì´í„° í¬ê¸°: {df.shape}\")\n",
    "print(f\"ğŸ“‹ ì´ í–‰ ìˆ˜: {df.shape[0]:,}ê°œ\")\n",
    "print(f\"ğŸ“‹ ì´ ì—´ ìˆ˜: {df.shape[1]}ê°œ\")\n",
    "print(f\"ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\nğŸ“‹ ì»¬ëŸ¼ ëª©ë¡:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-info",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° íƒ€ì… ë° ìƒì„¸ ì •ë³´\n",
    "print(\"ğŸ“‹ ë°ì´í„° íƒ€ì… ë° ê²°ì¸¡ê°’ ì •ë³´\")\n",
    "print(\"=\"*70)\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ” ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5í–‰)\")\n",
    "print(\"=\"*70)\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ” ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (í•˜ìœ„ 5í–‰)\")\n",
    "print(\"=\"*70)\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ìˆ í†µê³„ ì •ë³´\n",
    "print(\"ğŸ“ˆ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê¸°ìˆ í†µê³„\")\n",
    "print(\"=\"*70)\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\nğŸ“ ë²”ì£¼í˜• ë³€ìˆ˜ ê¸°ìˆ í†µê³„\")\n",
    "print(\"=\"*70)\n",
    "display(df.describe(include=['object']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-analysis-section",
   "metadata": {},
   "source": [
    "## ğŸ” 3. ê²°ì¸¡ê°’ ë¶„ì„\n",
    "\n",
    "ë°ì´í„°ì˜ í’ˆì§ˆì„ í™•ì¸í•˜ê³  ê²°ì¸¡ê°’ ì²˜ë¦¬ ì „ëµì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ì¸¡ê°’ í˜„í™© ë¶„ì„\n",
    "print(\"ğŸ” ê²°ì¸¡ê°’ í˜„í™© ë¶„ì„\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_info = pd.DataFrame({\n",
    "    'ê²°ì¸¡ê°’ ê°œìˆ˜': df.isnull().sum(),\n",
    "    'ê²°ì¸¡ê°’ ë¹„ìœ¨(%)': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "})\n",
    "\n",
    "# ê²°ì¸¡ê°’ì´ ìˆëŠ” ì»¬ëŸ¼ë§Œ í‘œì‹œ\n",
    "missing_columns = missing_info[missing_info['ê²°ì¸¡ê°’ ê°œìˆ˜'] > 0]\n",
    "if not missing_columns.empty:\n",
    "    missing_columns = missing_columns.sort_values('ê²°ì¸¡ê°’ ê°œìˆ˜', ascending=False)\n",
    "    display(missing_columns)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ê²°ì¸¡ê°’ ìš”ì•½:\")\n",
    "    print(f\"   â€¢ ê²°ì¸¡ê°’ì´ ìˆëŠ” ì»¬ëŸ¼: {len(missing_columns)}ê°œ\")\n",
    "    print(f\"   â€¢ ì „ì²´ ê²°ì¸¡ê°’ ê°œìˆ˜: {df.isnull().sum().sum():,}ê°œ\")\n",
    "    print(f\"   â€¢ ì „ì²´ ë°ì´í„° ëŒ€ë¹„ ê²°ì¸¡ê°’ ë¹„ìœ¨: {(df.isnull().sum().sum() / df.size * 100):.2f}%\")\n",
    "else:\n",
    "    print(\"âœ… ê²°ì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# ê²°ì¸¡ê°’ ì‹œê°í™”\n",
    "if not missing_columns.empty:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    missing_columns['ê²°ì¸¡ê°’ ê°œìˆ˜'].plot(kind='bar', color='lightcoral')\n",
    "    plt.title('ê²°ì¸¡ê°’ ê°œìˆ˜')\n",
    "    plt.ylabel('ê°œìˆ˜')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    missing_columns['ê²°ì¸¡ê°’ ë¹„ìœ¨(%)'].plot(kind='bar', color='skyblue')\n",
    "    plt.title('ê²°ì¸¡ê°’ ë¹„ìœ¨')\n",
    "    plt.ylabel('ë¹„ìœ¨ (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda-section",
   "metadata": {},
   "source": [
    "## ğŸ“Š 4. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA)\n",
    "\n",
    "ë°ì´í„°ì˜ ë¶„í¬ì™€ íŒ¨í„´ì„ ì‹œê°ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "target-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íƒ€ê²Ÿ ë³€ìˆ˜(ê°€ê²©) ë¶„í¬ ë¶„ì„\n",
    "print(\"ğŸ’° íƒ€ê²Ÿ ë³€ìˆ˜ (ê°€ê²©) ë¶„í¬ ë¶„ì„\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ê°€ê²© ê¸°ë³¸ í†µê³„\n",
    "price_stats = df['price_in_aed'].describe()\n",
    "print(\"ğŸ“Š ê°€ê²© í†µê³„:\")\n",
    "for stat, value in price_stats.items():\n",
    "    if stat in ['count']:\n",
    "        print(f\"   â€¢ {stat}: {value:,.0f}\")\n",
    "    else:\n",
    "        print(f\"   â€¢ {stat}: {value:,.0f} AED\")\n",
    "\n",
    "# ê°€ê²© ë¶„í¬ ì‹œê°í™”\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('ğŸš— ì¤‘ê³ ì°¨ ê°€ê²© ë¶„í¬ ë¶„ì„', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. ì›ë³¸ ê°€ê²© íˆìŠ¤í† ê·¸ë¨\n",
    "axes[0,0].hist(df['price_in_aed'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_title('ê°€ê²© ë¶„í¬ (ì›ë³¸)')\n",
    "axes[0,0].set_xlabel('ê°€ê²© (AED)')\n",
    "axes[0,0].set_ylabel('ë¹ˆë„ìˆ˜')\n",
    "axes[0,0].ticklabel_format(style='plain', axis='x')\n",
    "\n",
    "# 2. ë¡œê·¸ ë³€í™˜ ê°€ê²© íˆìŠ¤í† ê·¸ë¨\n",
    "axes[0,1].hist(np.log1p(df['price_in_aed']), bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[0,1].set_title('ê°€ê²© ë¶„í¬ (ë¡œê·¸ ë³€í™˜)')\n",
    "axes[0,1].set_xlabel('Log(ê°€ê²© + 1)')\n",
    "axes[0,1].set_ylabel('ë¹ˆë„ìˆ˜')\n",
    "\n",
    "# 3. ê°€ê²© ë°•ìŠ¤í”Œë¡¯\n",
    "axes[1,0].boxplot(df['price_in_aed'])\n",
    "axes[1,0].set_title('ê°€ê²© ë°•ìŠ¤í”Œë¡¯')\n",
    "axes[1,0].set_ylabel('ê°€ê²© (AED)')\n",
    "axes[1,0].ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "# 4. ê°€ê²© ëˆ„ì ë¶„í¬\n",
    "sorted_prices = np.sort(df['price_in_aed'])\n",
    "p = np.arange(len(sorted_prices)) / (len(sorted_prices) - 1)\n",
    "axes[1,1].plot(sorted_prices, p, linewidth=2, color='purple')\n",
    "axes[1,1].set_title('ê°€ê²© ëˆ„ì ë¶„í¬')\n",
    "axes[1,1].set_xlabel('ê°€ê²© (AED)')\n",
    "axes[1,1].set_ylabel('ëˆ„ì  í™•ë¥ ')\n",
    "axes[1,1].ticklabel_format(style='plain', axis='x')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ê°€ê²© êµ¬ê°„ë³„ ë¶„í¬\n",
    "price_ranges = {\n",
    "    'ì €ê°€ (5ë§Œ ì´í•˜)': (0, 50000),\n",
    "    'ì¤‘ì €ê°€ (5-10ë§Œ)': (50000, 100000),\n",
    "    'ì¤‘ê°„ (10-20ë§Œ)': (100000, 200000),\n",
    "    'ì¤‘ê³ ê°€ (20-50ë§Œ)': (200000, 500000),\n",
    "    'ê³ ê°€ (50ë§Œ ì´ìƒ)': (500000, float('inf'))\n",
    "}\n",
    "\n",
    "print(\"\\nğŸ’° ê°€ê²© êµ¬ê°„ë³„ ì°¨ëŸ‰ ë¶„í¬:\")\n",
    "for range_name, (min_price, max_price) in price_ranges.items():\n",
    "    count = len(df[(df['price_in_aed'] > min_price) & (df['price_in_aed'] <= max_price)])\n",
    "    percentage = count / len(df) * 100\n",
    "    print(f\"   â€¢ {range_name}: {count:,}ëŒ€ ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "categorical-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì£¼ìš” ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„ì„\n",
    "print(\"ğŸ·ï¸ ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„ì„\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "categorical_cols = ['company', 'body_type', 'fuel_type', 'transmission_type', 'emirate']\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(20, 18))\n",
    "fig.suptitle('ğŸ·ï¸ ì£¼ìš” ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„í¬', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    if col in df.columns:\n",
    "        row, col_idx = divmod(i, 2)\n",
    "        \n",
    "        # ìƒìœ„ 10ê°œ ì¹´í…Œê³ ë¦¬ë§Œ í‘œì‹œ\n",
    "        top_categories = df[col].value_counts().head(10)\n",
    "        \n",
    "        # íŒŒì´ ì°¨íŠ¸\n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, len(top_categories)))\n",
    "        wedges, texts, autotexts = axes[row, col_idx].pie(\n",
    "            top_categories.values, \n",
    "            labels=top_categories.index, \n",
    "            autopct='%1.1f%%',\n",
    "            colors=colors,\n",
    "            startangle=90\n",
    "        )\n",
    "        axes[row, col_idx].set_title(f'{col.replace(\"_\", \" \").title()} ë¶„í¬ (ìƒìœ„ 10ê°œ)')\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ í¬ê¸° ì¡°ì •\n",
    "        for autotext in autotexts:\n",
    "            autotext.set_fontsize(8)\n",
    "        for text in texts:\n",
    "            text.set_fontsize(8)\n",
    "        \n",
    "        print(f\"\\nğŸ“Š {col} í†µê³„:\")\n",
    "        print(f\"   â€¢ ê³ ìœ ê°’ ê°œìˆ˜: {df[col].nunique()}ê°œ\")\n",
    "        print(f\"   â€¢ ìµœë¹ˆê°’: {df[col].mode().iloc[0]} ({df[col].value_counts().iloc[0]}íšŒ, {df[col].value_counts().iloc[0]/len(df)*100:.1f}%)\")\n",
    "\n",
    "# ë¹ˆ subplot ì œê±°\n",
    "if len(categorical_cols) < 6:\n",
    "    axes[2, 1].remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë“¤ ê°„ì˜ ìƒê´€ê´€ê³„ ë¶„ì„\n",
    "print(\"ğŸ”¢ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìƒê´€ê´€ê³„ ë¶„ì„\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì„ íƒ\n",
    "numeric_cols = ['price_in_aed', 'kilometers', 'year']\n",
    "numeric_df = df[numeric_cols].copy()\n",
    "\n",
    "# year ì»¬ëŸ¼ì˜ ê²°ì¸¡ê°’ì„ ì¤‘ì•™ê°’ìœ¼ë¡œ ì„ì‹œ ì²˜ë¦¬\n",
    "numeric_df['year'] = numeric_df['year'].fillna(numeric_df['year'].median())\n",
    "\n",
    "# ìƒê´€ê´€ê³„ ê³„ì‚°\n",
    "correlation_matrix = numeric_df.corr()\n",
    "\n",
    "print(\"ğŸ“Š ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤:\")\n",
    "display(correlation_matrix.round(3))\n",
    "\n",
    "# ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ\n",
    "plt.figure(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))  # ìƒì‚¼ê°í˜• ë§ˆìŠ¤í¬\n",
    "sns.heatmap(\n",
    "    correlation_matrix, \n",
    "    mask=mask,\n",
    "    annot=True, \n",
    "    cmap='RdYlBu_r', \n",
    "    center=0,\n",
    "    square=True, \n",
    "    linewidths=0.5, \n",
    "    cbar_kws={'shrink': .8},\n",
    "    fmt='.3f'\n",
    ")\n",
    "plt.title('ğŸ”¢ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ ìƒê´€ê´€ê³„ í•´ì„:\")\n",
    "print(\"   â€¢ +1ì— ê°€ê¹Œìš¸ìˆ˜ë¡: ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„\")\n",
    "print(\"   â€¢ -1ì— ê°€ê¹Œìš¸ìˆ˜ë¡: ê°•í•œ ìŒì˜ ìƒê´€ê´€ê³„\")\n",
    "print(\"   â€¢ 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡: ìƒê´€ê´€ê³„ ì—†ìŒ\")\n",
    "\n",
    "# ì£¼ìš” ìƒê´€ê´€ê³„ ë¶„ì„\n",
    "price_corr = correlation_matrix['price_in_aed'].drop('price_in_aed').sort_values(key=abs, ascending=False)\n",
    "print(f\"\\nğŸ“ˆ ê°€ê²©ê³¼ì˜ ìƒê´€ê´€ê³„:\")\n",
    "for var, corr in price_corr.items():\n",
    "    direction = \"ì–‘ì˜\" if corr > 0 else \"ìŒì˜\"\n",
    "    strength = \"ê°•í•œ\" if abs(corr) > 0.7 else \"ì¤‘ê°„\" if abs(corr) > 0.3 else \"ì•½í•œ\"\n",
    "    print(f\"   â€¢ {var}: {corr:.3f} ({strength} {direction} ìƒê´€ê´€ê³„)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing-section",
   "metadata": {},
   "source": [
    "## ğŸ”§ 5. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "\n",
    "ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµì„ ìœ„í•´ ë°ì´í„°ë¥¼ ì •ì œí•˜ê³  ë³€í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-preprocessing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ë°ì´í„° ë³µì‚¬ë³¸ ìƒì„±\n",
    "df_clean = df.copy()\n",
    "original_shape = df_clean.shape\n",
    "print(f\"ğŸ“ ì›ë³¸ ë°ì´í„° í¬ê¸°: {original_shape}\")\n",
    "\n",
    "# 1ë‹¨ê³„: ê·¹ë‹¨ê°’ ì œê±°\n",
    "print(\"\\n1ï¸âƒ£ ê·¹ë‹¨ê°’ ì œê±° (ê°€ê²© ê¸°ì¤€ 1%~99% ë¶„ìœ„ìˆ˜)\")\n",
    "price_q01 = df_clean['price_in_aed'].quantile(0.01)\n",
    "price_q99 = df_clean['price_in_aed'].quantile(0.99)\n",
    "print(f\"   â€¢ 1% ë¶„ìœ„ìˆ˜: {price_q01:,.0f} AED\")\n",
    "print(f\"   â€¢ 99% ë¶„ìœ„ìˆ˜: {price_q99:,.0f} AED\")\n",
    "\n",
    "df_clean = df_clean[\n",
    "    (df_clean['price_in_aed'] >= price_q01) & \n",
    "    (df_clean['price_in_aed'] <= price_q99)\n",
    "]\n",
    "removed_count = original_shape[0] - df_clean.shape[0]\n",
    "print(f\"   â€¢ ì œê±°ëœ í–‰: {removed_count:,}ê°œ ({removed_count/original_shape[0]*100:.2f}%)\")\n",
    "print(f\"   â€¢ í˜„ì¬ ë°ì´í„° í¬ê¸°: {df_clean.shape}\")\n",
    "\n",
    "# 2ë‹¨ê³„: ê²°ì¸¡ê°’ ì²˜ë¦¬\n",
    "print(\"\\n2ï¸âƒ£ ê²°ì¸¡ê°’ ì²˜ë¦¬\")\n",
    "\n",
    "# year ì»¬ëŸ¼ ì²˜ë¦¬\n",
    "if 'year' in df_clean.columns:\n",
    "    year_missing = df_clean['year'].isnull().sum()\n",
    "    if year_missing > 0:\n",
    "        year_median = df_clean['year'].median()\n",
    "        df_clean['year'] = df_clean['year'].fillna(year_median)\n",
    "        print(f\"   â€¢ year ì»¬ëŸ¼: {year_missing:,}ê°œ ê²°ì¸¡ê°’ì„ ì¤‘ì•™ê°’ {year_median}ìœ¼ë¡œ ëŒ€ì²´\")\n",
    "\n",
    "# horsepower ì»¬ëŸ¼ ì²˜ë¦¬\n",
    "if 'horsepower' in df_clean.columns:\n",
    "    hp_missing = df_clean['horsepower'].isnull().sum()\n",
    "    if hp_missing > 0:\n",
    "        df_clean['horsepower'] = df_clean['horsepower'].fillna('Unknown')\n",
    "        print(f\"   â€¢ horsepower ì»¬ëŸ¼: {hp_missing:,}ê°œ ê²°ì¸¡ê°’ì„ 'Unknown'ìœ¼ë¡œ ëŒ€ì²´\")\n",
    "\n",
    "# 3ë‹¨ê³„: íŒŒìƒ ë³€ìˆ˜ ìƒì„±\n",
    "print(\"\\n3ï¸âƒ£ íŒŒìƒ ë³€ìˆ˜ ìƒì„±\")\n",
    "current_year = 2024\n",
    "if 'year' in df_clean.columns:\n",
    "    df_clean['car_age'] = current_year - df_clean['year']\n",
    "    print(f\"   â€¢ car_age ì»¬ëŸ¼ ìƒì„±: {current_year} - year\")\n",
    "    print(f\"   â€¢ ì°¨ëŸ‰ ì—°ì‹ ë²”ìœ„: {df_clean['car_age'].min():.0f}~{df_clean['car_age'].max():.0f}ë…„\")\n",
    "\n",
    "print(f\"\\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ í›„ ë°ì´í„° í¬ê¸°: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4ë‹¨ê³„: ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
    "print(\"4ï¸âƒ£ ë²”ì£¼í˜• ë³€ìˆ˜ ë¼ë²¨ ì¸ì½”ë”©\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# ì¸ì½”ë”©í•  ë²”ì£¼í˜• íŠ¹ì„±ë“¤\n",
    "categorical_features = [\n",
    "    'company', 'model', 'body_type', 'fuel_type', \n",
    "    'transmission_type', 'emirate', 'color', 'horsepower'\n",
    "]\n",
    "\n",
    "# ë¼ë²¨ ì¸ì½”ë” ë”•ì…”ë„ˆë¦¬ (ë‚˜ì¤‘ì— ì—­ë³€í™˜í•  ë•Œ ì‚¬ìš©)\n",
    "label_encoders = {}\n",
    "encoding_info = {}\n",
    "\n",
    "for feature in categorical_features:\n",
    "    if feature in df_clean.columns:\n",
    "        # ê²°ì¸¡ê°’ì„ 'Unknown'ìœ¼ë¡œ ì²˜ë¦¬\n",
    "        df_clean[feature] = df_clean[feature].fillna('Unknown')\n",
    "        \n",
    "        # ë¼ë²¨ ì¸ì½”ë”©\n",
    "        le = LabelEncoder()\n",
    "        df_clean[f'{feature}_encoded'] = le.fit_transform(df_clean[feature])\n",
    "        \n",
    "        # ì¸ì½”ë” ì €ì¥\n",
    "        label_encoders[feature] = le\n",
    "        \n",
    "        # ì¸ì½”ë”© ì •ë³´ ì €ì¥\n",
    "        unique_count = len(le.classes_)\n",
    "        encoding_info[feature] = {\n",
    "            'unique_count': unique_count,\n",
    "            'most_frequent': df_clean[feature].mode().iloc[0],\n",
    "            'encoded_range': f'0~{unique_count-1}'\n",
    "        }\n",
    "        \n",
    "        print(f\"   â€¢ {feature}: {unique_count}ê°œ ì¹´í…Œê³ ë¦¬ â†’ {encoding_info[feature]['encoded_range']}\")\n",
    "        print(f\"     ìµœë¹ˆê°’: {encoding_info[feature]['most_frequent']}\")\n",
    "\n",
    "print(f\"\\nâœ… ì´ {len(encoding_info)}ê°œ ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”© ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5ë‹¨ê³„: íŠ¹ì„± ì„ íƒ ë° ë°ì´í„° ë¶„í• \n",
    "print(\"5ï¸âƒ£ íŠ¹ì„± ì„ íƒ ë° ë°ì´í„° ë¶„í• \")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# ëª¨ë¸ë§ì— ì‚¬ìš©í•  íŠ¹ì„±ë“¤ ì„ íƒ\n",
    "feature_columns = [\n",
    "    'kilometers',               # ì£¼í–‰ê±°ë¦¬\n",
    "    'car_age',                 # ì°¨ëŸ‰ ì—°ì‹\n",
    "    'company_encoded',         # ì œì¡°ì‚¬ (ì¸ì½”ë”©)\n",
    "    'body_type_encoded',       # ì°¨ì²´ íƒ€ì… (ì¸ì½”ë”©)\n",
    "    'fuel_type_encoded',       # ì—°ë£Œ íƒ€ì… (ì¸ì½”ë”©)\n",
    "    'transmission_type_encoded', # ë³€ì†ê¸° íƒ€ì… (ì¸ì½”ë”©)\n",
    "    'emirate_encoded',         # ì§€ì—­ (ì¸ì½”ë”©)\n",
    "    'horsepower_encoded'       # ë§ˆë ¥ (ì¸ì½”ë”©)\n",
    "]\n",
    "\n",
    "# ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "available_features = [col for col in feature_columns if col in df_clean.columns]\n",
    "missing_features = [col for col in feature_columns if col not in df_clean.columns]\n",
    "\n",
    "print(f\"ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„±: {len(available_features)}ê°œ\")\n",
    "for i, feature in enumerate(available_features, 1):\n",
    "    print(f\"   {i:2d}. {feature}\")\n",
    "\n",
    "if missing_features:\n",
    "    print(f\"\\nâš ï¸ ëˆ„ë½ëœ íŠ¹ì„±: {len(missing_features)}ê°œ\")\n",
    "    for feature in missing_features:\n",
    "        print(f\"   â€¢ {feature}\")\n",
    "\n",
    "# íŠ¹ì„±(X)ê³¼ íƒ€ê²Ÿ(y) ë¶„ë¦¬\n",
    "X = df_clean[available_features]\n",
    "y = df_clean['price_in_aed']\n",
    "\n",
    "print(f\"\\nğŸ“ ìµœì¢… ë°ì´í„° í¬ê¸°:\")\n",
    "print(f\"   â€¢ íŠ¹ì„± í–‰ë ¬ (X): {X.shape}\")\n",
    "print(f\"   â€¢ íƒ€ê²Ÿ ë²¡í„° (y): {y.shape}\")\n",
    "print(f\"   â€¢ ê²°ì¸¡ê°’ í™•ì¸: {X.isnull().sum().sum()}ê°œ\")\n",
    "\n",
    "# í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• \n",
    "print(\"\\nğŸ“Š í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í•  (8:2 ë¹„ìœ¨)\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼\n",
    "    stratify=None     # íšŒê·€ ë¬¸ì œì´ë¯€ë¡œ ì¸µí™”ì¶”ì¶œ ì•ˆí•¨\n",
    ")\n",
    "\n",
    "print(f\"   â€¢ í›ˆë ¨ ë°ì´í„°: {X_train.shape} (ì „ì²´ì˜ {len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   â€¢ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape} (ì „ì²´ì˜ {len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬:\")\n",
    "print(f\"   â€¢ í›ˆë ¨ ì„¸íŠ¸ í‰ê·  ê°€ê²©: {y_train.mean():,.0f} AED\")\n",
    "print(f\"   â€¢ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê·  ê°€ê²©: {y_test.mean():,.0f} AED\")\n",
    "print(f\"   â€¢ ê°€ê²© ë¶„í¬ ì°¨ì´: {abs(y_train.mean() - y_test.mean()):,.0f} AED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-scaling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6ë‹¨ê³„: ë°ì´í„° í‘œì¤€í™”\n",
    "print(\"6ï¸âƒ£ ë°ì´í„° í‘œì¤€í™” (StandardScaler)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# í‘œì¤€í™” ì „ í†µê³„\n",
    "print(\"í‘œì¤€í™” ì „:\")\n",
    "print(f\"   â€¢ í‰ê· : {X_train.mean().mean():.2f}\")\n",
    "print(f\"   â€¢ í‘œì¤€í¸ì°¨: {X_train.std().mean():.2f}\")\n",
    "print(f\"   â€¢ ìµœì†Ÿê°’: {X_train.min().min():.2f}\")\n",
    "print(f\"   â€¢ ìµœëŒ“ê°’: {X_train.max().max():.2f}\")\n",
    "\n",
    "# StandardScaler ì ìš©\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # í›ˆë ¨ ë°ì´í„°ë¡œ ìŠ¤ì¼€ì¼ëŸ¬ í•™ìŠµ ë° ë³€í™˜\n",
    "X_test_scaled = scaler.transform(X_test)        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë³€í™˜ (ë™ì¼í•œ ìŠ¤ì¼€ì¼ëŸ¬ ì‚¬ìš©)\n",
    "\n",
    "# í‘œì¤€í™” í›„ í†µê³„\n",
    "print(\"\\ní‘œì¤€í™” í›„:\")\n",
    "print(f\"   â€¢ í‰ê· : {X_train_scaled.mean():.6f}\")\n",
    "print(f\"   â€¢ í‘œì¤€í¸ì°¨: {X_train_scaled.std():.6f}\")\n",
    "print(f\"   â€¢ ìµœì†Ÿê°’: {X_train_scaled.min():.2f}\")\n",
    "print(f\"   â€¢ ìµœëŒ“ê°’: {X_train_scaled.max():.2f}\")\n",
    "\n",
    "# ê° íŠ¹ì„±ë³„ ìŠ¤ì¼€ì¼ë§ ì •ë³´\n",
    "scaling_info = pd.DataFrame({\n",
    "    'Feature': available_features,\n",
    "    'Original_Mean': X_train.mean().values,\n",
    "    'Original_Std': X_train.std().values,\n",
    "    'Scaled_Mean': X_train_scaled.mean(axis=0),\n",
    "    'Scaled_Std': X_train_scaled.std(axis=0)\n",
    "})\n",
    "\n",
    "print(\"\\nğŸ“Š íŠ¹ì„±ë³„ ìŠ¤ì¼€ì¼ë§ ì •ë³´:\")\n",
    "display(scaling_info.round(4))\n",
    "\n",
    "print(\"\\nâœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“ ìµœì¢… í•™ìŠµ ë°ì´í„°: X_train_scaled {X_train_scaled.shape}, y_train {y_train.shape}\")\n",
    "print(f\"ğŸ“ ìµœì¢… í…ŒìŠ¤íŠ¸ ë°ì´í„°: X_test_scaled {X_test_scaled.shape}, y_test {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modeling-section",
   "metadata": {},
   "source": [
    "## ğŸ¤– 6. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ êµ¬í˜„\n",
    "\n",
    "ë‹¤ì–‘í•œ íšŒê·€ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-training-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ë° ë¹„êµ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ì‚¬ìš©í•  ëª¨ë¸ë“¤ ì •ì˜\n",
    "models = {\n",
    "    'Linear Regression': {\n",
    "        'model': LinearRegression(),\n",
    "        'description': 'ê¸°ë³¸ ì„ í˜•íšŒê·€ ëª¨ë¸ (ê·œì œ ì—†ìŒ)'\n",
    "    },\n",
    "    'Ridge Regression': {\n",
    "        'model': Ridge(alpha=1.0, random_state=42),\n",
    "        'description': 'L2 ê·œì œë¥¼ ì ìš©í•œ Ridge íšŒê·€ (ê³¼ì í•© ë°©ì§€)'\n",
    "    },\n",
    "    'Lasso Regression': {\n",
    "        'model': Lasso(alpha=1.0, random_state=42, max_iter=2000),\n",
    "        'description': 'L1 ê·œì œë¥¼ ì ìš©í•œ Lasso íšŒê·€ (íŠ¹ì„± ì„ íƒ íš¨ê³¼)'\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'model': ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42, max_iter=2000),\n",
    "        'description': 'L1ê³¼ L2 ê·œì œë¥¼ ê²°í•©í•œ ElasticNet (ê· í˜•ì¡íŒ ê·œì œ)'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ğŸ¯ ì‚¬ìš©í•  ëª¨ë¸ë“¤:\")\n",
    "for i, (name, info) in enumerate(models.items(), 1):\n",
    "    print(f\"   {i}. {name}: {info['description']}\")\n",
    "\n",
    "# ëª¨ë¸ ì„±ëŠ¥ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
    "model_results = {}\n",
    "trained_models = {}  # í•™ìŠµëœ ëª¨ë¸ë“¤ì„ ì €ì¥\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_name, model_info in models.items():\n",
    "    print(f\"\\nğŸ”„ {model_name} í•™ìŠµ ì¤‘...\")\n",
    "    \n",
    "    model = model_info['model']\n",
    "    \n",
    "    # ëª¨ë¸ í•™ìŠµ\n",
    "    start_time = pd.Timestamp.now()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    training_time = (pd.Timestamp.now() - start_time).total_seconds()\n",
    "    \n",
    "    # ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    \n",
    "    train_rmse = np.sqrt(train_mse)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    \n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # êµì°¨ ê²€ì¦ ìˆ˜í–‰ (5-fold)\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    model_results[model_name] = {\n",
    "        'Train MAE': train_mae,\n",
    "        'Test MAE': test_mae,\n",
    "        'Train RMSE': train_rmse,\n",
    "        'Test RMSE': test_rmse,\n",
    "        'Train RÂ²': train_r2,\n",
    "        'Test RÂ²': test_r2,\n",
    "        'CV RÂ² Mean': cv_mean,\n",
    "        'CV RÂ² Std': cv_std,\n",
    "        'Training Time': training_time\n",
    "    }\n",
    "    \n",
    "    trained_models[model_name] = model\n",
    "    \n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(f\"   âœ… í•™ìŠµ ì™„ë£Œ ({training_time:.2f}ì´ˆ)\")\n",
    "    print(f\"   ğŸ“Š ì„±ëŠ¥ ì§€í‘œ:\")\n",
    "    print(f\"      â€¢ í›ˆë ¨ MAE: {train_mae:,.0f} AED\")\n",
    "    print(f\"      â€¢ í…ŒìŠ¤íŠ¸ MAE: {test_mae:,.0f} AED\")\n",
    "    print(f\"      â€¢ í›ˆë ¨ RÂ²: {train_r2:.4f}\")\n",
    "    print(f\"      â€¢ í…ŒìŠ¤íŠ¸ RÂ²: {test_r2:.4f}\")\n",
    "    print(f\"      â€¢ êµì°¨ê²€ì¦ RÂ²: {cv_mean:.4f} (Â±{cv_std:.4f})\")\n",
    "    \n",
    "    # ê³¼ì í•© ì²´í¬\n",
    "    overfitting = train_r2 - test_r2\n",
    "    if overfitting > 0.1:\n",
    "        print(f\"      âš ï¸ ê³¼ì í•© ì˜ì‹¬ (RÂ² ì°¨ì´: {overfitting:.3f})\")\n",
    "    elif overfitting > 0.05:\n",
    "        print(f\"      âš¡ ê²½ë¯¸í•œ ê³¼ì í•© (RÂ² ì°¨ì´: {overfitting:.3f})\")\n",
    "    else:\n",
    "        print(f\"      âœ… ì–‘í˜¸í•œ ì¼ë°˜í™” (RÂ² ì°¨ì´: {overfitting:.3f})\")\n",
    "\n",
    "print(\"\\nğŸ‰ ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-results-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ì •ë¦¬\n",
    "print(\"ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "results_df = pd.DataFrame(model_results).T\n",
    "\n",
    "print(\"ğŸ† ì „ì²´ ì„±ëŠ¥ ë¹„êµí‘œ:\")\n",
    "display(results_df.round(4))\n",
    "\n",
    "# ìµœì  ëª¨ë¸ ì„ ì • (í…ŒìŠ¤íŠ¸ RÂ² ê¸°ì¤€)\n",
    "best_model_name = results_df['Test RÂ²'].idxmax()\n",
    "best_r2 = results_df.loc[best_model_name, 'Test RÂ²']\n",
    "best_mae = results_df.loc[best_model_name, 'Test MAE']\n",
    "best_cv_mean = results_df.loc[best_model_name, 'CV RÂ² Mean']\n",
    "best_cv_std = results_df.loc[best_model_name, 'CV RÂ² Std']\n",
    "\n",
    "print(f\"\\nğŸ¥‡ ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name}\")\n",
    "print(f\"   ğŸ“ˆ í…ŒìŠ¤íŠ¸ RÂ² ì ìˆ˜: {best_r2:.4f} ({best_r2*100:.1f}% ì„¤ëª…ë ¥)\")\n",
    "print(f\"   ğŸ“‰ í…ŒìŠ¤íŠ¸ MAE: {best_mae:,.0f} AED\")\n",
    "print(f\"   ğŸ”„ êµì°¨ê²€ì¦ RÂ²: {best_cv_mean:.4f} (Â±{best_cv_std:.4f})\")\n",
    "print(f\"   ğŸ’¡ ì‹¤ì œ ê°€ê²© ëŒ€ë¹„ í‰ê·  ì˜¤ì°¨ìœ¨: {best_mae/y_test.mean()*100:.1f}%\")\n",
    "\n",
    "# ì„±ëŠ¥ ìˆœìœ„ ìƒì„±\n",
    "print(\"\\nğŸ… ëª¨ë¸ ìˆœìœ„ (í…ŒìŠ¤íŠ¸ RÂ² ê¸°ì¤€):\")\n",
    "rank_df = results_df[['Test RÂ²', 'Test MAE', 'CV RÂ² Mean']].copy()\n",
    "rank_df = rank_df.sort_values('Test RÂ²', ascending=False)\n",
    "\n",
    "for i, (model_name, row) in enumerate(rank_df.iterrows(), 1):\n",
    "    medal = [\"ğŸ¥‡\", \"ğŸ¥ˆ\", \"ğŸ¥‰\"][i-1] if i <= 3 else f\"{i}.\"\n",
    "    print(f\"   {medal} {model_name}: RÂ² = {row['Test RÂ²']:.4f}, MAE = {row['Test MAE']:,.0f} AED\")\n",
    "\n",
    "# ê° ì§€í‘œë³„ ìµœê³  ì„±ëŠ¥ ëª¨ë¸\n",
    "print(\"\\nğŸ¯ ì§€í‘œë³„ ìµœê³  ì„±ëŠ¥:\")\n",
    "metrics = {\n",
    "    'Test RÂ² (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)': results_df['Test RÂ²'].idxmax(),\n",
    "    'Test MAE (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)': results_df['Test MAE'].idxmin(),\n",
    "    'CV RÂ² Mean (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)': results_df['CV RÂ² Mean'].idxmax(),\n",
    "    'Training Time (ë¹ ë¥¼ìˆ˜ë¡ ì¢‹ìŒ)': results_df['Training Time'].idxmin()\n",
    "}\n",
    "\n",
    "for metric, best_model in metrics.items():\n",
    "    value = results_df.loc[best_model, metric.split('(')[0].strip()]\n",
    "    if 'Time' in metric:\n",
    "        print(f\"   â€¢ {metric}: {best_model} ({value:.2f}ì´ˆ)\")\n",
    "    elif 'MAE' in metric:\n",
    "        print(f\"   â€¢ {metric}: {best_model} ({value:,.0f} AED)\")\n",
    "    else:\n",
    "        print(f\"   â€¢ {metric}: {best_model} ({value:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization-section",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ 7. ëª¨ë¸ ì„±ëŠ¥ ì‹œê°í™” ë° ë¶„ì„\n",
    "\n",
    "í•™ìŠµëœ ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ì„ ë‹¤ì–‘í•œ ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "performance-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì„±ëŠ¥ ì¢…í•© ì‹œê°í™”\n",
    "print(\"ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ ì‹œê°í™”\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "fig.suptitle('ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì„±ëŠ¥ ì¢…í•© ë¶„ì„', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. í…ŒìŠ¤íŠ¸ MAE ë¹„êµ\n",
    "mae_values = results_df['Test MAE'].sort_values()\n",
    "colors_mae = ['gold' if idx == best_model_name else 'lightcoral' for idx in mae_values.index]\n",
    "bars1 = axes[0,0].bar(range(len(mae_values)), mae_values, color=colors_mae)\n",
    "axes[0,0].set_title('í…ŒìŠ¤íŠ¸ MAE ë¹„êµ\\n(ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)')\n",
    "axes[0,0].set_ylabel('MAE (AED)')\n",
    "axes[0,0].set_xticks(range(len(mae_values)))\n",
    "axes[0,0].set_xticklabels(mae_values.index, rotation=45, ha='right')\n",
    "axes[0,0].ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "# ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ\n",
    "for i, (bar, value) in enumerate(zip(bars1, mae_values)):\n",
    "    axes[0,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(mae_values)*0.01,\n",
    "                  f'{value:,.0f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 2. í…ŒìŠ¤íŠ¸ RÂ² ë¹„êµ\n",
    "r2_values = results_df['Test RÂ²'].sort_values(ascending=False)\n",
    "colors_r2 = ['gold' if idx == best_model_name else 'lightgreen' for idx in r2_values.index]\n",
    "bars2 = axes[0,1].bar(range(len(r2_values)), r2_values, color=colors_r2)\n",
    "axes[0,1].set_title('í…ŒìŠ¤íŠ¸ RÂ² ë¹„êµ\\n(ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)')\n",
    "axes[0,1].set_ylabel('RÂ² Score')\n",
    "axes[0,1].set_xticks(range(len(r2_values)))\n",
    "axes[0,1].set_xticklabels(r2_values.index, rotation=45, ha='right')\n",
    "axes[0,1].set_ylim(0, 1)\n",
    "\n",
    "# ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ\n",
    "for i, (bar, value) in enumerate(zip(bars2, r2_values)):\n",
    "    axes[0,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                  f'{value:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 3. êµì°¨ê²€ì¦ RÂ² ë¹„êµ (ì—ëŸ¬ë°” í¬í•¨)\n",
    "cv_mean = results_df['CV RÂ² Mean']\n",
    "cv_std = results_df['CV RÂ² Std']\n",
    "x_pos = range(len(cv_mean))\n",
    "colors_cv = ['gold' if idx == best_model_name else 'skyblue' for idx in cv_mean.index]\n",
    "bars3 = axes[0,2].bar(x_pos, cv_mean, yerr=cv_std, capsize=5, color=colors_cv, alpha=0.7)\n",
    "axes[0,2].set_title('êµì°¨ê²€ì¦ RÂ²\\n(ì—ëŸ¬ë°”: Â±1 í‘œì¤€í¸ì°¨)')\n",
    "axes[0,2].set_ylabel('CV RÂ² Score')\n",
    "axes[0,2].set_xticks(x_pos)\n",
    "axes[0,2].set_xticklabels(cv_mean.index, rotation=45, ha='right')\n",
    "axes[0,2].set_ylim(0, 1)\n",
    "\n",
    "# 4. í›ˆë ¨ vs í…ŒìŠ¤íŠ¸ MAE (ê³¼ì í•© í™•ì¸)\n",
    "x_pos = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "axes[1,0].bar(x_pos - width/2, results_df['Train MAE'], width, \n",
    "              label='Train MAE', alpha=0.8, color='lightblue')\n",
    "axes[1,0].bar(x_pos + width/2, results_df['Test MAE'], width, \n",
    "              label='Test MAE', alpha=0.8, color='orange')\n",
    "axes[1,0].set_title('í›ˆë ¨ vs í…ŒìŠ¤íŠ¸ MAE\\n(ê³¼ì í•© í™•ì¸)')\n",
    "axes[1,0].set_ylabel('MAE (AED)')\n",
    "axes[1,0].set_xticks(x_pos)\n",
    "axes[1,0].set_xticklabels(results_df.index, rotation=45, ha='right')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "# 5. í›ˆë ¨ vs í…ŒìŠ¤íŠ¸ RÂ² (ê³¼ì í•© í™•ì¸)\n",
    "axes[1,1].bar(x_pos - width/2, results_df['Train RÂ²'], width, \n",
    "              label='Train RÂ²', alpha=0.8, color='lightgreen')\n",
    "axes[1,1].bar(x_pos + width/2, results_df['Test RÂ²'], width, \n",
    "              label='Test RÂ²', alpha=0.8, color='coral')\n",
    "axes[1,1].set_title('í›ˆë ¨ vs í…ŒìŠ¤íŠ¸ RÂ²\\n(ê³¼ì í•© í™•ì¸)')\n",
    "axes[1,1].set_ylabel('RÂ² Score')\n",
    "axes[1,1].set_xticks(x_pos)\n",
    "axes[1,1].set_xticklabels(results_df.index, rotation=45, ha='right')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].set_ylim(0, 1)\n",
    "\n",
    "# 6. í•™ìŠµ ì‹œê°„ ë¹„êµ\n",
    "time_values = results_df['Training Time'].sort_values()\n",
    "colors_time = ['lightsteelblue'] * len(time_values)\n",
    "bars6 = axes[1,2].bar(range(len(time_values)), time_values, color=colors_time)\n",
    "axes[1,2].set_title('ëª¨ë¸ í•™ìŠµ ì‹œê°„')\n",
    "axes[1,2].set_ylabel('ì‹œê°„ (ì´ˆ)')\n",
    "axes[1,2].set_xticks(range(len(time_values)))\n",
    "axes[1,2].set_xticklabels(time_values.index, rotation=45, ha='right')\n",
    "\n",
    "# ì‹œê°„ ê°’ í‘œì‹œ\n",
    "for i, (bar, value) in enumerate(zip(bars6, time_values)):\n",
    "    axes[1,2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(time_values)*0.01,\n",
    "                  f'{value:.2f}s', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ê³¼ì í•© ë¶„ì„\n",
    "print(\"\\nğŸ” ê³¼ì í•© ë¶„ì„:\")\n",
    "print(\"=\"*50)\n",
    "for model_name in results_df.index:\n",
    "    train_r2 = results_df.loc[model_name, 'Train RÂ²']\n",
    "    test_r2 = results_df.loc[model_name, 'Test RÂ²']\n",
    "    gap = train_r2 - test_r2\n",
    "    \n",
    "    if gap > 0.1:\n",
    "        status = \"âš ï¸ ì‹¬ê°í•œ ê³¼ì í•©\"\n",
    "    elif gap > 0.05:\n",
    "        status = \"âš¡ ê²½ë¯¸í•œ ê³¼ì í•©\"\n",
    "    else:\n",
    "        status = \"âœ… ì–‘í˜¸í•œ ì¼ë°˜í™”\"\n",
    "    \n",
    "    print(f\"   â€¢ {model_name}: Train-Test RÂ² ì°¨ì´ = {gap:+.3f} ({status})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "best-model-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì  ëª¨ë¸ ìƒì„¸ ë¶„ì„\n",
    "print(f\"ğŸ¥‡ ìµœì  ëª¨ë¸ '{best_model_name}' ìƒì„¸ ë¶„ì„\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ìµœì  ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "best_model = trained_models[best_model_name]\n",
    "y_test_pred_best = best_model.predict(X_test_scaled)\n",
    "y_train_pred_best = best_model.predict(X_train_scaled)\n",
    "\n",
    "# ì˜ˆì¸¡ ê²°ê³¼ ìƒì„¸ ë¶„ì„\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle(f'ğŸ” {best_model_name} ì˜ˆì¸¡ ê²°ê³¼ ìƒì„¸ ë¶„ì„', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 1. ì‹¤ì œ vs ì˜ˆì¸¡ê°’ ì‚°ì ë„\n",
    "axes[0,0].scatter(y_test, y_test_pred_best, alpha=0.6, color='blue', s=30)\n",
    "# ì™„ë²½í•œ ì˜ˆì¸¡ì„  (y=x)\n",
    "min_val = min(y_test.min(), y_test_pred_best.min())\n",
    "max_val = max(y_test.max(), y_test_pred_best.max())\n",
    "axes[0,0].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='ì™„ë²½í•œ ì˜ˆì¸¡ì„ ')\n",
    "axes[0,0].set_xlabel('ì‹¤ì œ ê°€ê²© (AED)')\n",
    "axes[0,0].set_ylabel('ì˜ˆì¸¡ ê°€ê²© (AED)')\n",
    "axes[0,0].set_title('ì‹¤ì œ vs ì˜ˆì¸¡ ê°€ê²©')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].ticklabel_format(style='plain')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. ì”ì°¨(ì˜¤ì°¨) ë¶„í¬\n",
    "residuals = y_test - y_test_pred_best\n",
    "axes[0,1].hist(residuals, bins=30, alpha=0.7, color='orange', edgecolor='black')\n",
    "axes[0,1].axvline(0, color='red', linestyle='--', linewidth=2, label='ì™„ë²½í•œ ì˜ˆì¸¡ (ì˜¤ì°¨=0)')\n",
    "axes[0,1].axvline(residuals.mean(), color='green', linestyle='--', linewidth=2, \n",
    "                 label=f'í‰ê·  ì˜¤ì°¨: {residuals.mean():.0f} AED')\n",
    "axes[0,1].set_xlabel('ì”ì°¨ (ì‹¤ì œ - ì˜ˆì¸¡) (AED)')\n",
    "axes[0,1].set_ylabel('ë¹ˆë„ìˆ˜')\n",
    "axes[0,1].set_title('ì”ì°¨ ë¶„í¬')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].ticklabel_format(style='plain', axis='x')\n",
    "\n",
    "# 3. ì”ì°¨ vs ì˜ˆì¸¡ê°’ (ë“±ë¶„ì‚°ì„± í™•ì¸)\n",
    "axes[1,0].scatter(y_test_pred_best, residuals, alpha=0.6, color='purple', s=30)\n",
    "axes[1,0].axhline(y=0, color='red', linestyle='--', linewidth=2, label='ì˜¤ì°¨ = 0')\n",
    "axes[1,0].set_xlabel('ì˜ˆì¸¡ ê°€ê²© (AED)')\n",
    "axes[1,0].set_ylabel('ì”ì°¨ (AED)')\n",
    "axes[1,0].set_title('ì˜ˆì¸¡ê°’ vs ì”ì°¨\\n(ë“±ë¶„ì‚°ì„± í™•ì¸)')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].ticklabel_format(style='plain')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. ì˜ˆì¸¡ ì˜¤ì°¨ì˜ ì ˆëŒ“ê°’ ë¶„í¬\n",
    "abs_errors = np.abs(residuals)\n",
    "axes[1,1].hist(abs_errors, bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[1,1].axvline(abs_errors.mean(), color='red', linestyle='--', linewidth=2, \n",
    "                 label=f'í‰ê·  ì ˆëŒ€ì˜¤ì°¨: {abs_errors.mean():.0f} AED')\n",
    "axes[1,1].axvline(abs_errors.median(), color='blue', linestyle='--', linewidth=2, \n",
    "                 label=f'ì¤‘ì•™ ì ˆëŒ€ì˜¤ì°¨: {abs_errors.median():.0f} AED')\n",
    "axes[1,1].set_xlabel('ì ˆëŒ€ ì˜¤ì°¨ (AED)')\n",
    "axes[1,1].set_ylabel('ë¹ˆë„ìˆ˜')\n",
    "axes[1,1].set_title('ì ˆëŒ€ ì˜¤ì°¨ ë¶„í¬')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].ticklabel_format(style='plain', axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ì˜ˆì¸¡ ì •í™•ë„ ìƒì„¸ ë¶„ì„\n",
    "print(\"\\nğŸ¯ ì˜ˆì¸¡ ì •í™•ë„ ìƒì„¸ ë¶„ì„:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "accuracy_ranges = [5000, 10000, 20000, 30000, 50000]\n",
    "print(\"ì˜¤ì°¨ ë²”ìœ„ë³„ ì˜ˆì¸¡ ì •í™•ë„:\")\n",
    "for range_val in accuracy_ranges:\n",
    "    accuracy = np.mean(np.abs(residuals) <= range_val) * 100\n",
    "    print(f\"   â€¢ Â±{range_val:,} AED ë‚´ ì •í™•ë„: {accuracy:.1f}%\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ì˜¤ì°¨ í†µê³„ ìš”ì•½:\")\n",
    "print(f\"   â€¢ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE): {mean_absolute_error(y_test, y_test_pred_best):,.0f} AED\")\n",
    "print(f\"   â€¢ í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (RMSE): {np.sqrt(mean_squared_error(y_test, y_test_pred_best)):,.0f} AED\")\n",
    "print(f\"   â€¢ í‰ê·  í¸í–¥ (Bias): {residuals.mean():,.0f} AED\")\n",
    "print(f\"   â€¢ ì˜¤ì°¨ í‘œì¤€í¸ì°¨: {residuals.std():,.0f} AED\")\n",
    "print(f\"   â€¢ ì‹¤ì œ ê°€ê²© í‰ê· : {y_test.mean():,.0f} AED\")\n",
    "print(f\"   â€¢ í‰ê·  ìƒëŒ€ ì˜¤ì°¨: {abs(residuals.mean())/y_test.mean()*100:.2f}%\")\n",
    "print(f\"   â€¢ ì¤‘ì•™ ì ˆëŒ€ ì˜¤ì°¨: {np.median(np.abs(residuals)):,.0f} AED\")\n",
    "\n",
    "# ê·¹ë‹¨ ì‚¬ë¡€ ë¶„ì„\n",
    "max_error_idx = np.abs(residuals).idxmax()\n",
    "min_error_idx = np.abs(residuals).idxmin()\n",
    "\n",
    "print(f\"\\nğŸ” ê·¹ë‹¨ ì‚¬ë¡€ ë¶„ì„:\")\n",
    "print(f\"   â€¢ ìµœëŒ€ ì˜¤ì°¨: {abs(residuals[max_error_idx]):,.0f} AED\")\n",
    "print(f\"     - ì‹¤ì œ: {y_test[max_error_idx]:,.0f} AED\")\n",
    "print(f\"     - ì˜ˆì¸¡: {y_test_pred_best[list(y_test.index).index(max_error_idx)]:,.0f} AED\")\n",
    "print(f\"   â€¢ ìµœì†Œ ì˜¤ì°¨: {abs(residuals[min_error_idx]):,.0f} AED\")\n",
    "print(f\"     - ì‹¤ì œ: {y_test[min_error_idx]:,.0f} AED\")\n",
    "print(f\"     - ì˜ˆì¸¡: {y_test_pred_best[list(y_test.index).index(min_error_idx)]:,.0f} AED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-importance-section",
   "metadata": {},
   "source": [
    "## ğŸ” 8. íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„\n",
    "\n",
    "ìµœì  ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì–´ë–¤ íŠ¹ì„±ì´ ì¤‘ê³ ì°¨ ê°€ê²©ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ë¶„ì„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-importance-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ” íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Ridge/Lasso/ElasticNet ëª¨ë¸ì˜ ê³„ìˆ˜ ë¶„ì„\n",
    "if best_model_name in ['Ridge Regression', 'Lasso Regression', 'ElasticNet', 'Linear Regression']:\n",
    "    \n",
    "    # ëª¨ë¸ ê³„ìˆ˜ ì¶”ì¶œ\n",
    "    coefficients = best_model.coef_\n",
    "    \n",
    "    # íŠ¹ì„± ì¤‘ìš”ë„ DataFrame ìƒì„±\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': available_features,\n",
    "        'Coefficient': coefficients,\n",
    "        'Abs_Coefficient': np.abs(coefficients)\n",
    "    })\n",
    "    \n",
    "    # ì ˆëŒ“ê°’ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ì¤‘ìš”ë„ ìˆœ)\n",
    "    feature_importance = feature_importance.sort_values('Abs_Coefficient', ascending=False)\n",
    "    \n",
    "    print(f\"ğŸ“Š {best_model_name} ëª¨ë¸ì˜ íŠ¹ì„± ì¤‘ìš”ë„:\")\n",
    "    display(feature_importance.round(4))\n",
    "    \n",
    "    # íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    fig.suptitle(f'ğŸ” {best_model_name} íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. ê³„ìˆ˜ ê°’ (ì–‘ìˆ˜/ìŒìˆ˜ êµ¬ë¶„)\n",
    "    colors = ['red' if coef < 0 else 'blue' for coef in feature_importance['Coefficient']]\n",
    "    bars1 = axes[0].barh(range(len(feature_importance)), feature_importance['Coefficient'], \n",
    "                        color=colors, alpha=0.7)\n",
    "    axes[0].set_yticks(range(len(feature_importance)))\n",
    "    axes[0].set_yticklabels([f.replace('_encoded', '') for f in feature_importance['Feature']])\n",
    "    axes[0].set_xlabel('ê³„ìˆ˜ ê°’')\n",
    "    axes[0].set_title('íŠ¹ì„±ë³„ ê³„ìˆ˜ ê°’\\n(ë¹¨ê°•: ìŒìˆ˜, íŒŒë‘: ì–‘ìˆ˜)')\n",
    "    axes[0].axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ê³„ìˆ˜ ê°’ í‘œì‹œ\n",
    "    for i, (bar, coef) in enumerate(zip(bars1, feature_importance['Coefficient'])):\n",
    "        x_pos = coef + (0.5 if coef >= 0 else -0.5)\n",
    "        axes[0].text(x_pos, bar.get_y() + bar.get_height()/2, f'{coef:.1f}', \n",
    "                    ha='left' if coef >= 0 else 'right', va='center', fontsize=9)\n",
    "    \n",
    "    # 2. ì ˆëŒ“ê°’ ì¤‘ìš”ë„\n",
    "    bars2 = axes[1].barh(range(len(feature_importance)), feature_importance['Abs_Coefficient'], \n",
    "                        color='green', alpha=0.7)\n",
    "    axes[1].set_yticks(range(len(feature_importance)))\n",
    "    axes[1].set_yticklabels([f.replace('_encoded', '') for f in feature_importance['Feature']])\n",
    "    axes[1].set_xlabel('ì ˆëŒ“ê°’ ì¤‘ìš”ë„')\n",
    "    axes[1].set_title('íŠ¹ì„± ì¤‘ìš”ë„ (ì ˆëŒ“ê°’ ê¸°ì¤€)')\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ì¤‘ìš”ë„ ê°’ í‘œì‹œ\n",
    "    for i, (bar, importance) in enumerate(zip(bars2, feature_importance['Abs_Coefficient'])):\n",
    "        axes[1].text(importance + max(feature_importance['Abs_Coefficient'])*0.01, \n",
    "                    bar.get_y() + bar.get_height()/2, f'{importance:.1f}', \n",
    "                    ha='left', va='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # íŠ¹ì„±ë³„ í•´ì„\n",
    "    print(\"\\nğŸ’¡ íŠ¹ì„±ë³„ ê°€ê²© ì˜í–¥ í•´ì„:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    feature_interpretations = {\n",
    "        'kilometers': 'ì£¼í–‰ê±°ë¦¬ (km)',\n",
    "        'car_age': 'ì°¨ëŸ‰ ì—°ì‹ (ë…„)',\n",
    "        'company_encoded': 'ì œì¡°ì‚¬ ë¸Œëœë“œ',\n",
    "        'body_type_encoded': 'ì°¨ì²´ íƒ€ì…',\n",
    "        'fuel_type_encoded': 'ì—°ë£Œ íƒ€ì…',\n",
    "        'transmission_type_encoded': 'ë³€ì†ê¸° íƒ€ì…',\n",
    "        'emirate_encoded': 'íŒë§¤ ì§€ì—­',\n",
    "        'horsepower_encoded': 'ì—”ì§„ ë§ˆë ¥'\n",
    "    }\n",
    "    \n",
    "    print(\"ìƒìœ„ 5ê°œ ì¤‘ìš” íŠ¹ì„±:\")\n",
    "    for i, (idx, row) in enumerate(feature_importance.head(5).iterrows(), 1):\n",
    "        feature_name = row['Feature']\n",
    "        coef = row['Coefficient']\n",
    "        abs_coef = row['Abs_Coefficient']\n",
    "        \n",
    "        # ì˜í–¥ ë°©í–¥\n",
    "        direction = \"ê°€ê²© ìƒìŠ¹\" if coef > 0 else \"ê°€ê²© í•˜ë½\"\n",
    "        feature_desc = feature_interpretations.get(feature_name, feature_name)\n",
    "        \n",
    "        print(f\"   {i}. {feature_desc}\")\n",
    "        print(f\"      â€¢ ê³„ìˆ˜: {coef:+.2f} ({direction} ìš”ì¸)\")\n",
    "        print(f\"      â€¢ ì¤‘ìš”ë„: {abs_coef:.2f}\")\n",
    "        \n",
    "        # êµ¬ì²´ì ì¸ í•´ì„\n",
    "        if feature_name == 'kilometers':\n",
    "            if coef < 0:\n",
    "                print(f\"      â†’ ì£¼í–‰ê±°ë¦¬ê°€ 1,000km ì¦ê°€í•  ë•Œë§ˆë‹¤ ì•½ {abs(coef*1000):,.0f} AED ê°€ê²© í•˜ë½\")\n",
    "        elif feature_name == 'car_age':\n",
    "            if coef < 0:\n",
    "                print(f\"      â†’ ì°¨ëŸ‰ì´ 1ë…„ ì˜¤ë˜ë  ë•Œë§ˆë‹¤ ì•½ {abs(coef):,.0f} AED ê°€ê²© í•˜ë½\")\n",
    "        print()\n",
    "    \n",
    "    # Lassoì˜ ê²½ìš° 0ì¸ ê³„ìˆ˜ë“¤ í™•ì¸\n",
    "    if best_model_name == 'Lasso Regression':\n",
    "        zero_coefs = feature_importance[feature_importance['Coefficient'] == 0]\n",
    "        if not zero_coefs.empty:\n",
    "            print(f\"ğŸ” Lasso ê·œì œë¡œ ì œê±°ëœ íŠ¹ì„± ({len(zero_coefs)}ê°œ):\")\n",
    "            for feature in zero_coefs['Feature']:\n",
    "                feature_desc = feature_interpretations.get(feature, feature)\n",
    "                print(f\"   â€¢ {feature_desc} (ê³„ìˆ˜ = 0)\")\n",
    "            print(\"   â†’ ì´ íŠ¹ì„±ë“¤ì€ ê°€ê²© ì˜ˆì¸¡ì— ê±°ì˜ ê¸°ì—¬í•˜ì§€ ì•ŠëŠ” ê²ƒìœ¼ë¡œ íŒë‹¨ë¨\")\n",
    "\n",
    "else:\n",
    "    print(f\"âš ï¸ {best_model_name}ì€ ì„ í˜• ëª¨ë¸ì´ ì•„ë‹ˆë¯€ë¡œ ê³„ìˆ˜ ê¸°ë°˜ íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ì´ ë¶ˆê°€í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"\\nâœ… íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "business-insights-section",
   "metadata": {},
   "source": [
    "## ğŸ’¼ 9. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë° ê²°ë¡ \n",
    "\n",
    "ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œì˜ ì¸ì‚¬ì´íŠ¸ì™€ ì‹¤ë¬´ í™œìš© ë°©ì•ˆì„ ì œì‹œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "business-insights",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë° ì‹¤ë¬´ í™œìš© ë°©ì•ˆ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ì „ì²´ ë¶„ì„ ê²°ê³¼ ìš”ì•½\n",
    "total_samples = len(df_clean)\n",
    "avg_price = y.mean()\n",
    "price_std = y.std()\n",
    "best_mae = results_df.loc[best_model_name, 'Test MAE']\n",
    "best_r2 = results_df.loc[best_model_name, 'Test RÂ²']\n",
    "\n",
    "print(\"ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½:\")\n",
    "print(f\"   â€¢ ë¶„ì„ ë°ì´í„°: {total_samples:,}ëŒ€ì˜ ì¤‘ê³ ì°¨\")\n",
    "print(f\"   â€¢ í‰ê·  ê°€ê²©: {avg_price:,.0f} AED (í‘œì¤€í¸ì°¨: {price_std:,.0f})\")\n",
    "print(f\"   â€¢ ìµœì  ëª¨ë¸: {best_model_name}\")\n",
    "print(f\"   â€¢ ì˜ˆì¸¡ ì •í™•ë„: RÂ² = {best_r2:.3f} ({best_r2*100:.1f}% ì„¤ëª…ë ¥)\")\n",
    "print(f\"   â€¢ í‰ê·  ì˜¤ì°¨: Â±{best_mae:,.0f} AED ({best_mae/avg_price*100:.1f}%)\")\n",
    "\n",
    "# ì„±ëŠ¥ ë“±ê¸‰ í‰ê°€\n",
    "if best_r2 >= 0.9:\n",
    "    performance_grade = \"ğŸ† íƒì›” (ìƒìš©í™” ìˆ˜ì¤€)\"\n",
    "elif best_r2 >= 0.8:\n",
    "    performance_grade = \"ğŸ¥‡ ìš°ìˆ˜ (ì‹¤ë¬´ í™œìš© ê°€ëŠ¥)\"\n",
    "elif best_r2 >= 0.7:\n",
    "    performance_grade = \"ğŸ¥ˆ ì–‘í˜¸ (ë³´ì¡° ë„êµ¬ë¡œ í™œìš©)\"\n",
    "elif best_r2 >= 0.6:\n",
    "    performance_grade = \"ğŸ¥‰ ë³´í†µ (ì°¸ê³ ìš©)\"\n",
    "else:\n",
    "    performance_grade = \"âš ï¸ ë¶€ì¡± (ê°œì„  í•„ìš”)\"\n",
    "\n",
    "print(f\"   â€¢ ì„±ëŠ¥ ë“±ê¸‰: {performance_grade}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ” í•µì‹¬ ë°œê²¬ì‚¬í•­\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ê°€ê²© ê²°ì • ìš”ì¸ ë¶„ì„\n",
    "if best_model_name in ['Ridge Regression', 'Lasso Regression', 'ElasticNet', 'Linear Regression']:\n",
    "    top_features = feature_importance.head(3)\n",
    "    \n",
    "    print(\"ğŸ’° ì£¼ìš” ê°€ê²© ê²°ì • ìš”ì¸ (ì˜í–¥ë ¥ ìˆœ):\")\n",
    "    for i, (idx, row) in enumerate(top_features.iterrows(), 1):\n",
    "        feature_name = row['Feature'].replace('_encoded', '')\n",
    "        coef = row['Coefficient']\n",
    "        impact = \"ìƒìŠ¹\" if coef > 0 else \"í•˜ë½\"\n",
    "        print(f\"   {i}. {feature_name}: ê°€ê²© {impact} ì£¼ìš” ìš”ì¸ (ê³„ìˆ˜: {coef:+.1f})\")\n",
    "\n",
    "# ê°ê°€ìƒê° ë¶„ì„\n",
    "if 'car_age' in available_features and best_model_name in ['Ridge Regression', 'Lasso Regression', 'ElasticNet', 'Linear Regression']:\n",
    "    age_coef = feature_importance[feature_importance['Feature'] == 'car_age']['Coefficient'].iloc[0]\n",
    "    if age_coef < 0:\n",
    "        annual_depreciation = abs(age_coef)\n",
    "        print(f\"\\nğŸ“‰ ê°ê°€ìƒê° íŒ¨í„´:\")\n",
    "        print(f\"   â€¢ ì—°ê°„ í‰ê·  ê°€ì¹˜ í•˜ë½: {annual_depreciation:,.0f} AED\")\n",
    "        print(f\"   â€¢ 5ë…„ í›„ ëˆ„ì  ê°€ì¹˜ í•˜ë½: {annual_depreciation * 5:,.0f} AED\")\n",
    "        \n",
    "        # ì‹ ì°¨ ê°€ê²©ë³„ ì”ì¡´ê°€ì¹˜ ì˜ˆì¸¡\n",
    "        new_car_prices = [50000, 100000, 200000, 300000]\n",
    "        print(f\"   â€¢ ì‹ ì°¨ ê°€ê²©ë³„ 5ë…„ í›„ ì˜ˆìƒ ì”ì¡´ê°€ì¹˜:\")\n",
    "        for price in new_car_prices:\n",
    "            residual_value = price - (annual_depreciation * 5)\n",
    "            residual_rate = residual_value / price * 100\n",
    "            print(f\"     - {price:,} AED â†’ {residual_value:,.0f} AED ({residual_rate:.0f}%)\")\n",
    "\n",
    "# ì£¼í–‰ê±°ë¦¬ ì˜í–¥ ë¶„ì„\n",
    "if 'kilometers' in available_features and best_model_name in ['Ridge Regression', 'Lasso Regression', 'ElasticNet', 'Linear Regression']:\n",
    "    km_coef = feature_importance[feature_importance['Feature'] == 'kilometers']['Coefficient'].iloc[0]\n",
    "    if km_coef != 0:\n",
    "        km_impact = abs(km_coef)\n",
    "        print(f\"\\nğŸ›£ï¸ ì£¼í–‰ê±°ë¦¬ ì˜í–¥:\")\n",
    "        if km_coef < 0:\n",
    "            print(f\"   â€¢ 1,000km ì¶”ê°€ ì£¼í–‰ ì‹œ ê°€ì¹˜ í•˜ë½: {km_impact * 1000:,.0f} AED\")\n",
    "            print(f\"   â€¢ ì €ì£¼í–‰(3ë§Œkm) vs ê³ ì£¼í–‰(10ë§Œkm) ê°€ê²© ì°¨ì´: {km_impact * 70000:,.0f} AED\")\n",
    "        else:\n",
    "            print(f\"   â€¢ ì£¼í–‰ê±°ë¦¬ì™€ ê°€ê²©ì´ ì–‘ì˜ ìƒê´€ê´€ê³„ (íŠ¹ì´ ì¼€ì´ìŠ¤)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸš€ ì‹¤ë¬´ í™œìš© ì‹œë‚˜ë¦¬ì˜¤\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "use_cases = {\n",
    "    'ğŸª ì¤‘ê³ ì°¨ ë”œëŸ¬ì‹­': [\n",
    "        f'ë§¤ì… ê°€ê²© ì±…ì •: ì˜ˆìƒ ì˜¤ì°¨ Â±{best_mae:,.0f} AED ë²”ìœ„ ë‚´ì—ì„œ ì•ˆì „í•œ ë§¤ì…ê°€ ê²°ì •',\n",
    "        'ì¬ê³  íšŒì „ìœ¨ í–¥ìƒ: ì‹œì¥ê°€ ëŒ€ë¹„ ì ì • íŒë§¤ê°€ê²© ì„¤ì •ìœ¼ë¡œ ë¹ ë¥¸ íŒë§¤ ì´‰ì§„',\n",
    "        'ìˆ˜ìµì„± ë¶„ì„: ì°¨ëŸ‰ë³„ ì˜ˆìƒ ë§ˆì§„ ê³„ì‚°ìœ¼ë¡œ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”'\n",
    "    ],\n",
    "    'ğŸ‘¥ ì¼ë°˜ ì†Œë¹„ì': [\n",
    "        'êµ¬ë§¤ ì˜ì‚¬ê²°ì •: ì‹œì¥ê°€ ëŒ€ë¹„ ì €ë ´í•œ ë§¤ë¬¼ ì‹ë³„',\n",
    "        'íŒë§¤ ì‹œì  ê²°ì •: ì°¨ëŸ‰ ê°€ì¹˜ ë³€í™” ì˜ˆì¸¡ìœ¼ë¡œ ìµœì  íŒë§¤ íƒ€ì´ë° ì„ íƒ',\n",
    "        'í˜‘ìƒë ¥ ê°•í™”: ë°ì´í„° ê¸°ë°˜ ì ì •ê°€ê²© ì •ë³´ë¡œ ê°€ê²© í˜‘ìƒ'\n",
    "    ],\n",
    "    'ğŸ¦ ê¸ˆìœµ ê¸°ê´€': [\n",
    "        'ë‹´ë³´ëŒ€ì¶œ ì‹¬ì‚¬: ì •í™•í•œ ì°¨ëŸ‰ ê°€ì¹˜ í‰ê°€ë¡œ ëŒ€ì¶œí•œë„ ì‚°ì •',\n",
    "        'ë¦¬ìŠ¤í¬ ê´€ë¦¬: ëŒ€ì¶œ ê¸°ê°„ ì¤‘ ë‹´ë³´ê°€ì¹˜ ë³€í™” ëª¨ë‹ˆí„°ë§',\n",
    "        'ë³´í—˜ ìƒí’ˆ: ì°¨ëŸ‰ ê°€ì¹˜ ê¸°ë°˜ ë³´í—˜ë£Œ ì±…ì • ë° ë³´ìƒê¸ˆ ì‚°ì •'\n",
    "    ],\n",
    "    'ğŸ“Š ì‹œì¥ ë¶„ì„ê°€': [\n",
    "        'ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„: ë¸Œëœë“œë³„, ì°¨ì¢…ë³„ ê°€ê²© ë™í–¥ íŒŒì•…',\n",
    "        'íˆ¬ì ì „ëµ: ê°€ì¹˜ í•˜ë½ì´ ì ì€ ì°¨ì¢… ì‹ë³„ë¡œ íˆ¬ì í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±',\n",
    "        'ì •ì±… ì˜í–¥ ë¶„ì„: ì—°ë£Œ ì •ì±…, í™˜ê²½ ê·œì œê°€ ì°¨ëŸ‰ ê°€ê²©ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ í‰ê°€'\n",
    "    ]\n",
    "}\n",
    "\n",
    "for category, scenarios in use_cases.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for scenario in scenarios:\n",
    "        print(f\"   â€¢ {scenario}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“ˆ ê¸°ëŒ€ íš¨ê³¼\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "benefits = [\n",
    "    f\"ğŸ’° ê±°ë˜ íš¨ìœ¨ì„± í–¥ìƒ: í‰ê·  {best_mae:,.0f} AED ì˜¤ì°¨ë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê°€ê²© ê¸°ì¤€ ì œê³µ\",\n",
    "    \"â° ì˜ì‚¬ê²°ì • ì‹œê°„ ë‹¨ì¶•: ìˆ˜ë™ ì‹œì„¸ ì¡°ì‚¬ ëŒ€ì‹  ì¦‰ì‹œ ê°€ê²© ì˜ˆì¸¡ ê°€ëŠ¥\",\n",
    "    \"ğŸ“Š íˆ¬ëª…ì„± ì¦ëŒ€: ê°ê´€ì  ë°ì´í„° ê¸°ë°˜ ê°€ê²© ì‚°ì •ìœ¼ë¡œ ì‹œì¥ ì‹ ë¢°ë„ í–¥ìƒ\",\n",
    "    \"ğŸ¯ ìœ„í—˜ ê°ì†Œ: ê³¼ëŒ€/ê³¼ì†Œ í‰ê°€ ë°©ì§€ë¡œ ì¬ì •ì  ì†ì‹¤ ìµœì†Œí™”\",\n",
    "    \"ğŸ“ˆ ì‹œì¥ ì„±ìˆ™ë„ í–¥ìƒ: ì •ë³´ ë¹„ëŒ€ì¹­ í•´ì†Œë¡œ ê±´ì „í•œ ê±°ë˜ í™˜ê²½ ì¡°ì„±\"\n",
    "]\n",
    "\n",
    "for benefit in benefits:\n",
    "    print(f\"   â€¢ {benefit}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âš ï¸ í•œê³„ì  ë° ì£¼ì˜ì‚¬í•­\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "limitations = [\n",
    "    f\"ğŸ“‰ ì˜ˆì¸¡ ì˜¤ì°¨: í‰ê·  Â±{best_mae:,.0f} AED ì˜¤ì°¨ ì¡´ì¬ (ì‹¤ì œ ê°€ê²©ì˜ ì•½ {best_mae/avg_price*100:.1f}%)\",\n",
    "    \"ğŸ• ì‹œì ì„± í•œê³„: í˜„ì¬ ì‹œì¥ ìƒí™© ë³€í™” (ê²½ì œ, ì—°ë£Œë¹„, ì •ì±… ë³€í™”) ë¯¸ë°˜ì˜\",\n",
    "    \"ğŸš— ê°œë³„ ì°¨ëŸ‰ íŠ¹ì„±: ì‚¬ê³  ì´ë ¥, ì •ë¹„ ìƒíƒœ, íŠ¹ìˆ˜ ì˜µì…˜ ë“± ê°œë³„ ìš”ì¸ ë¯¸ê³ ë ¤\",\n",
    "    \"ğŸŒ ì§€ì—­ì„± í•œê³„: UAE ì‹œì¥ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ë¥¸ ì§€ì—­ ì ìš© ì‹œ ì •í™•ë„ í•˜ë½ ê°€ëŠ¥\",\n",
    "    \"ğŸ“… ë°ì´í„° ì‹œì°¨: ëª¨ë¸ í•™ìŠµ ì‹œì  ì´í›„ ì‹œì¥ ë³€í™” ë°˜ì˜ ì§€ì—°\"\n",
    "]\n",
    "\n",
    "for limitation in limitations:\n",
    "    print(f\"   â€¢ {limitation}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ ê¶Œì¥ ì‚¬ìš©ë²•:\")\n",
    "print(\"   1. ëª¨ë¸ ì˜ˆì¸¡ê°’ì„ 'ì°¸ê³  ê¸°ì¤€'ìœ¼ë¡œ í™œìš© (ì ˆëŒ€ì  ê¸°ì¤€ ì•„ë‹˜)\")\n",
    "print(\"   2. ì‹¤ì œ ê±°ë˜ ì‹œ ì „ë¬¸ê°€ ì˜ê²¬ ë° ì‹œì¥ ìƒí™© ì¢…í•© ê³ ë ¤\")\n",
    "print(\"   3. ì •ê¸°ì  ëª¨ë¸ ì—…ë°ì´íŠ¸ë¡œ ì˜ˆì¸¡ ì •í™•ë„ ìœ ì§€\")\n",
    "print(f\"   4. Â±{best_mae:,.0f} AED ì˜¤ì°¨ ë²”ìœ„ ë‚´ì—ì„œ ê°€ê²© í˜‘ìƒ ì§„í–‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-improvements",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”® í–¥í›„ ê°œì„  ë°©ì•ˆ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"1ï¸âƒ£ ë°ì´í„° ê°œì„ :\")\n",
    "data_improvements = [\n",
    "    \"ğŸ“‹ ì¶”ê°€ íŠ¹ì„± ìˆ˜ì§‘: ì‚¬ê³  ì´ë ¥, ì •ë¹„ ê¸°ë¡, ì†Œìœ ì ìˆ˜, íŠ¹ìˆ˜ ì˜µì…˜ ë“±\",\n",
    "    \"ğŸ”— ì™¸ë¶€ ë°ì´í„° ì—°ë™: ì—°ë£Œê°€ê²©, ë³´í—˜ë£Œ, ê²½ì œì§€í‘œ, ê³„ì ˆì„± ìš”ì¸\",\n",
    "    \"â° ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸: ì‹œì¥ ë³€í™”ë¥¼ ë°˜ì˜í•œ ì§€ì†ì  ë°ì´í„° ìˆ˜ì§‘\",\n",
    "    \"ğŸŒ ë‹¤ì§€ì—­ í™•ì¥: ë‹¤ì–‘í•œ êµ­ê°€/ì§€ì—­ ë°ì´í„°ë¡œ ëª¨ë¸ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ\"\n",
    "]\n",
    "for improvement in data_improvements:\n",
    "    print(f\"   â€¢ {improvement}\")\n",
    "\n",
    "print(\"\\n2ï¸âƒ£ ëª¨ë¸ ê³ ë„í™”:\")\n",
    "model_improvements = [\n",
    "    \"ğŸŒ³ ì•™ìƒë¸” ëª¨ë¸: Random Forest, XGBoost, LightGBM ë“±ìœ¼ë¡œ ì˜ˆì¸¡ ì„±ëŠ¥ í–¥ìƒ\",\n",
    "    \"ğŸ§  ë”¥ëŸ¬ë‹ ëª¨ë¸: ì‹ ê²½ë§ìœ¼ë¡œ ë³µì¡í•œ ë¹„ì„ í˜• íŒ¨í„´ í•™ìŠµ\",\n",
    "    \"ğŸ¯ ì„¸ë¶„í™” ëª¨ë¸: ì°¨ì¢…ë³„, ê°€ê²©ëŒ€ë³„, ë¸Œëœë“œë³„ ì „ìš© ëª¨ë¸ ê°œë°œ\",\n",
    "    \"âš–ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”: GridSearch, Bayesian Optimization ì ìš©\",\n",
    "    \"ğŸ”„ ì˜¨ë¼ì¸ í•™ìŠµ: ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ëª¨ë¸ ì§€ì†ì  ì—…ë°ì´íŠ¸\"\n",
    "]\n",
    "for improvement in model_improvements:\n",
    "    print(f\"   â€¢ {improvement}\")\n",
    "\n",
    "print(\"\\n3ï¸âƒ£ ë¹„ì¦ˆë‹ˆìŠ¤ í™•ì¥:\")\n",
    "business_improvements = [\n",
    "    \"ğŸ“± ëª¨ë°”ì¼ ì•±: ì‹¤ì‹œê°„ ê°€ê²© ì¡°íšŒ ë° ì•Œë¦¼ ì„œë¹„ìŠ¤\",\n",
    "    \"ğŸ”Œ API ì„œë¹„ìŠ¤: ë”œëŸ¬ì‹­, ê¸ˆìœµê¸°ê´€ ëŒ€ìƒ B2B ì„œë¹„ìŠ¤\",\n",
    "    \"ğŸ¨ ê°œì¸í™”: ì‚¬ìš©ì ì„ í˜¸ë„ ê¸°ë°˜ ë§ì¶¤ ì¶”ì²œ ì‹œìŠ¤í…œ\",\n",
    "    \"ğŸ“Š ëŒ€ì‹œë³´ë“œ: ì‹œì¥ íŠ¸ë Œë“œ ë° ì¸ì‚¬ì´íŠ¸ ì œê³µ í”Œë«í¼\",\n",
    "    \"ğŸ¤– ì±—ë´‡: ìì—°ì–´ ê¸°ë°˜ ê°€ê²© ìƒë‹´ ì„œë¹„ìŠ¤\"\n",
    "]\n",
    "for improvement in business_improvements:\n",
    "    print(f\"   â€¢ {improvement}\")\n",
    "\n",
    "print(\"\\n4ï¸âƒ£ í’ˆì§ˆ ê´€ë¦¬:\")\n",
    "quality_improvements = [\n",
    "    \"ğŸ§ª A/B í…ŒìŠ¤íŠ¸: ëª¨ë¸ ì„±ëŠ¥ ì§€ì†ì  ëª¨ë‹ˆí„°ë§ ë° ê°œì„ \",\n",
    "    \"ğŸ”„ í”¼ë“œë°± ë£¨í”„: ì‹¤ì œ ê±°ë˜ ë°ì´í„°ì™€ ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ ë¶„ì„\",\n",
    "    \"ğŸ” ì„¤ëª… ê°€ëŠ¥í•œ AI: SHAP, LIME ë“±ìœ¼ë¡œ ì˜ˆì¸¡ ê·¼ê±° ì œê³µ\",\n",
    "    \"âš¡ ì„±ëŠ¥ ìµœì í™”: ëª¨ë¸ ê²½ëŸ‰í™”ë¡œ ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì†ë„ í–¥ìƒ\",\n",
    "    \"ğŸ›¡ï¸ ì´ìƒì¹˜ íƒì§€: ë¹„ì •ìƒì  ê°€ê²© ì˜ˆì¸¡ ìë™ ê°ì§€ ì‹œìŠ¤í…œ\"\n",
    "]\n",
    "for improvement in quality_improvements:\n",
    "    print(f\"   â€¢ {improvement}\")\n",
    "\n",
    "# ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ\n",
    "print(\"\\nğŸ“Š ê°œì„  í›„ ì˜ˆìƒ ì„±ëŠ¥:\")\n",
    "current_r2 = best_r2\n",
    "target_r2 = 0.85 if current_r2 < 0.85 else current_r2 + 0.05\n",
    "target_mae = best_mae * 0.8  # 20% ì˜¤ì°¨ ê°ì†Œ ëª©í‘œ\n",
    "\n",
    "print(f\"   â€¢ í˜„ì¬ RÂ²: {current_r2:.3f} â†’ ëª©í‘œ RÂ²: {target_r2:.3f}\")\n",
    "print(f\"   â€¢ í˜„ì¬ MAE: {best_mae:,.0f} AED â†’ ëª©í‘œ MAE: {target_mae:,.0f} AED\")\n",
    "print(f\"   â€¢ ì˜ˆìƒ ê°œì„ ë„: {(target_r2-current_r2)/current_r2*100:.1f}% RÂ² í–¥ìƒ, {(1-target_mae/best_mae)*100:.1f}% ì˜¤ì°¨ ê°ì†Œ\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“ í•™ìŠµ ì„±ê³¼ ë° ê²°ë¡ \")\n",
    "print(\"=\"*70)\n",
    "\n",
    "learning_outcomes = [\n",
    "    \"ğŸ“Š ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ë°ì´í„°ë¡œ ì™„ì „í•œ ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ê²½í—˜\",\n",
    "    \"ğŸ” íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)ë¶€í„° ëª¨ë¸ í‰ê°€ê¹Œì§€ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì´í•´\",\n",
    "    \"âš–ï¸ ë‹¤ì–‘í•œ íšŒê·€ ëª¨ë¸ ë¹„êµë¥¼ í†µí•œ ìµœì  ëª¨ë¸ ì„ íƒ ëŠ¥ë ¥ ìŠµë“\",\n",
    "    \"ğŸ’¡ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œ ë¶„ì„ ê²°ê³¼ í•´ì„ ë° ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ì—­ëŸ‰\",\n",
    "    \"ğŸ¯ ëª¨ë¸ì˜ í•œê³„ì  ì¸ì‹ ë° ì‹¤ë¬´ ì ìš© ì‹œ ê³ ë ¤ì‚¬í•­ íŒŒì•…\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ“š ì£¼ìš” í•™ìŠµ ì„±ê³¼:\")\n",
    "for outcome in learning_outcomes:\n",
    "    print(f\"   â€¢ {outcome}\")\n",
    "\n",
    "print(f\"\\nğŸ† ìµœì¢… ê²°ë¡ :\")\n",
    "print(f\"ì´ë²ˆ ì¤‘ê³ ì°¨ ê°€ê²© ì˜ˆì¸¡ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ {best_model_name} ëª¨ë¸ë¡œ \")\n",
    "print(f\"{best_r2*100:.1f}%ì˜ ì„¤ëª…ë ¥ê³¼ í‰ê·  Â±{best_mae:,.0f} AEDì˜ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.\")\n",
    "print(f\"ì´ëŠ” ì‹¤ë¬´ì—ì„œ ì°¸ê³ ìë£Œë¡œ í™œìš©í•˜ê¸°ì— ì¶©ë¶„í•œ ìˆ˜ì¤€ì´ë©°, ì§€ì†ì ì¸ ê°œì„ ì„ í†µí•´\")\n",
    "print(f\"ë”ìš± ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê°€ê²© ì˜ˆì¸¡ ì„œë¹„ìŠ¤ë¡œ ë°œì „ì‹œí‚¬ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"\\nğŸ‰ ì¤‘ê³ ì°¨ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ ë¶„ì„ ì™„ë£Œ! ğŸ‰\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}